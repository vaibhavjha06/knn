











import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.neighbors import KNeighborsRegressor

cars = pd.read_csv("/Users/vaibhavjha/knn/data/USA_cars_datasets.csv")
cars = cars.loc[:,('price', 'year', 'mileage')]
cars.head(15) # smaller df

cars['price'].isnull().sum()
cars['year'].isnull().sum()
cars['mileage'].isnull().sum() # There are no NA's to handle

cars.head(29)
cars.shape # 2499 x 3


# Max min normalize year and mileage

def maxmin(z):
    z = (z-min(z))-(max(z)-min(z))
    return(z)

normcars = cars[['year', 'mileage']].apply(maxmin)


from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(normcars, cars['price'], test_size=.2, random_state=100) # successfully split dataset into 80/20


from sklearn.neighbors import KNeighborsRegressor

for k in [3,10,25,50,100,300]:
    model = KNeighborsRegressor(n_neighbors=k).fit(X_train,Y_train) # fit the model on the training data with k neighbors
    Y_hat = model.predict(X_test) # performed prediction of Y_hat with input of X_test using the model built
    SSE = np.sum( (Y_test-Y_hat)**2 ) # calculated the SSE of predicted values of y (Y_hat) difference with true y values (Y_test)
    plot, axes = plt.subplots()
    plt.scatter(Y_test,Y_hat) # made a scatterplot of predicted y values and actual y values within test set
    plt.title('k: '+str(k)+', SSE: '+str(SSE)) # titles of plot
    axes.set_ylim(-1000, 62000)
    axes.set_xlim(-1000, 62000)
    plt.show()

# It seems that as k increases, the predictions tend to bunch together at the modal points of actual y. There is less variation among the data points.


k_bar = 200
k_grid = np.arange(1,k_bar) # The range of k's to consider
SSE = np.zeros(k_bar) 

for k in range(k_bar):
    fitted_model = KNeighborsRegressor(n_neighbors=k+1).fit(X_train,Y_train) 
    Y_hat = fitted_model.predict(X_test) # Predict values for test set
    SSE[k] = np.sum( (Y_test-Y_hat)**2 ) # Save the computed SSE
 
SSE_min = np.min(SSE) # Lowest recorded SSE
min_index = np.where(SSE==SSE_min) # Find the indices of y that equal the minimum
k_star = k_grid[min_index] # Find the optimal value of k
print(k_star)
# Prints [12]

plt.plot(np.arange(0,k_bar),SSE) # Plot SSE by k
plt.xlabel("k")
plt.title("optimal k:"+str(k_star))
plt.ylabel('SSE')
plt.show()
# 12 is the lowest point on the y-axis


















